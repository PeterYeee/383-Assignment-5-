{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3KijSLdDtfr"
      },
      "source": [
        "# Assignment 5: Introduction to Pytorch\n",
        "## PyTorch\n",
        "\n",
        "**PyTorch** is an open-source machine learning library for Python that is widely used for developing and training deep learning models.\n",
        "\n",
        "PyTorch provides two main features:\n",
        "\n",
        "1.  An n-dimensional **Tensor**, similar to NumPy but can run on GPUs.\n",
        "2.  Automatic differentiation for building and training neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_tzTvZujtuc"
      },
      "source": [
        "TODO: How many late days are you using for this assignment?\n",
        "Ans: ____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sk7qzM0EGy-"
      },
      "source": [
        "## Section 1: PyTorch Tensors\n",
        "\n",
        "- These next few code blocks introduce PyTorch tensors, covering their creation from lists and NumPy arrays, initialization with random values, ones, and zeros, and key attributes like shape, datatype, and device placement.\n",
        "- Please fill out the None values in the following cells with the appropriate functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRENraBbRgP"
      },
      "source": [
        "### Section 1.1 Creating Tensors\n",
        "\n",
        "##### Creating a Tensor from a List  \n",
        "PyTorch tensors are core to working with data and building models in PyTorch. They are important as they provide the foundation for efficient computation, especially for deep learning tasks. PyTorch tensors can be muti-dimensional and can be easily moved between GPU and CPU. To begin working with PyTorch, we will start by creating tensors.\n",
        "\n",
        "This cell imports the PyTorch library and initializes a 2D list. It includes a TODO to create a tensor from the list using `torch.tensor(data)`, but the assignment to `x_data` is currently set to `None`. The cell is intended to demonstrate creating a tensor from a Python list.  \n",
        "\n",
        "In the following section please update the **None** values with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 547,
      "metadata": {
        "id": "72_VWMUZDvLQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor from list:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the PyTorch library\n",
        "import torch\n",
        "\n",
        "# ### Creating Tensors\n",
        "data = [[1, 2], [3, 4]]\n",
        "# TODO: Create a tensor from a list and output the tensor\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Tensor from list:\\n {x_data} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfuanlyFYQto"
      },
      "source": [
        "##### Creating a Tensor from a NumPy Array  \n",
        "Pytorch provides an easy way to convert NumPy objects to PyTorch Tensors. We will explore this in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 548,
      "metadata": {
        "id": "5BBA_1RbGPky"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor from NumPy array:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "NumPy array from  tensor:\n",
            " [[1 2]\n",
            " [3 4]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array(data)\n",
        "# TODO: Create a tensor from a NumPy array\n",
        "x_np = torch.tensor(np_array)\n",
        "print(f\"Tensor from NumPy array:\\n {x_np} \\n\")\n",
        "# TODO: Convert the tensor back to a NumPy array\n",
        "x_np = x_np.numpy()\n",
        "print(f\"NumPy array from  tensor:\\n {x_np} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhuya3r7Yua0"
      },
      "source": [
        "##### Creating Tensors with Specific Values  \n",
        "This cell includes TODOs for creating tensors with specific properties:  \n",
        "- `x_ones`: A tensor of the same shape as `x_data`, filled with ones, retaining its properties.  \n",
        "- `x_rand`: A tensor of the same shape as `x_data`, filled with random values between 0 and 1, overriding its datatype.  \n",
        "- `rand_tensor`: A randomly initialized tensor with a specified shape `(2,3)`.  \n",
        "- `ones_tensor`: A tensor of shape `(2,3)` filled with ones.  \n",
        "- `zeros_tensor`: A tensor of shape `(2,3)` filled with zeros.  \n",
        "\n",
        "##### Tensor Attributes  \n",
        "The last part of this cell creates a random tensor of shape `(3,4)` and prints its attributes: shape, datatype, and the device it is stored on.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 549,
      "metadata": {
        "id": "rstUFSZuGVwG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5172, 0.4856],\n",
            "        [0.7948, 0.9792]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5135, 0.1988, 0.0053],\n",
            "        [0.1599, 0.5876, 0.1327]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# TODO: Create a tensor of same dimensions as x_data with ones in place\n",
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "#TODO: Creates a tensor of same dimensions as x_data with random values between 0 and 1\n",
        "x_rand =  torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n",
        "# Create a tensor with specified shape\n",
        "shape = (2,3,)\n",
        "\n",
        "# TODO: Fill out the following None values\n",
        "rand_tensor = torch.rand(shape) # A tensor of shape  (2,3,) with random values\n",
        "ones_tensor = torch.ones(shape) # A tensor of shape  (2,3,) with ones as values\n",
        "zeros_tensor = torch.zeros(shape) # A tensor of shape  (2,3,) with zeros as values\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "\n",
        "print()\n",
        "#### Tensor Attributes\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3wrp1HzbAXc"
      },
      "source": [
        "### Section 1.2 Moving Tensors from CPU to GPU\n",
        "One great benefit of PyTorch is that it enables us to easily use GPUs. In deep learning, we often use very large tensors with parallelizable operations. The architecture of GPU can accelerate these operation, allowing more efficient learning. In this section, we will learn how to move tensors to GPU.  This section has no TODOs and is for your information.\n",
        "\n",
        "Note: This code block will give different outputs depending on your access to a GPU.\n",
        "\n",
        "The cell output displays what output you would get if you run this cell using a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 550,
      "metadata": {
        "id": "t5Xdy7L6Gwr2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is not available, using CPU.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The output of this cell will be different depending on if your machine has access to a GPU\n",
        "# Observe what happens when running it in your current enviornment\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # Use the first available GPU\n",
        "    print(\"GPU is available!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available, using CPU.\")\n",
        "print()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = torch.rand(3,4)\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\") #By default, device is cpu\n",
        "  print('You are not using GPU yet!')\n",
        "  print()\n",
        "  tensor = tensor.to(device)\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "  print('Congrats, you are using GPU!')\n",
        "print()\n",
        "\n",
        "# Common Error\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        y_cpu = torch.randn(3,4)\n",
        "        result = tensor + y_cpu # Error! Tensors on different devices\n",
        "    except RuntimeError as e:\n",
        "        print(\"Error:\", e)\n",
        "        print(\"Remember: Move both tensors to the same device to perform operations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkZvB3PAb6UT"
      },
      "source": [
        "### Section 1.3 Tensor Operations\n",
        "\n",
        "Tensor operations in PyTorch include a variety of element-wise and matrix operations such as addition, subtraction, multiplication, and division. Common operations include:  \n",
        "\n",
        "- **Element-wise Operations**: Addition (`+`), subtraction (`-`), multiplication (`*`), and division (`/`).  \n",
        "- **Matrix Operations**: Matrix multiplication (`torch.matmul()` or `@` operator), transposition (`tensor.T`), and inversion.  \n",
        "- **Reduction Operations**: Summation (`torch.sum()`), mean (`torch.mean()`), max/min (`torch.max()` / `torch.min()`).  \n",
        "- **Reshaping**: Changing tensor dimensions using `torch.reshape()`, `torch.view()`, or `torch.permute()`.  \n",
        "- **Concatenation and Stacking**: `torch.cat()` for joining along a dimension, `torch.stack()` for stacking along a new dimension.  \n",
        "- **In-place Operations**: Operations ending in `_` (e.g., `tensor.add_()`) modify the tensor directly.  \n",
        "\n",
        "### TODO: In the following section please update the **None** values with your answer in the subsequent codeblocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 551,
      "metadata": {
        "id": "vUOVI2BPJbWm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "Updated tensor: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# ### Tensor Operations\n",
        "\n",
        "# TODO: Standard numpy-like indexing and slicing:\n",
        "tensor = torch.ones(4, 4)\n",
        "\n",
        "# TODO: print the first row of the tensor\n",
        "first_row = tensor[0]\n",
        "print('First row: ', first_row)\n",
        "\n",
        "# TODO: print the first column of the tensor\n",
        "first_column = tensor[:, 0]\n",
        "print('First column: ', first_column)\n",
        "\n",
        "# TODO: print the first column of the tensor\n",
        "last_column = tensor[:, -1]\n",
        "print('Last column:', last_column)\n",
        "\n",
        "# TODO: Update the tensor so that index 1 column is all zeros and print the tensor\n",
        "tensor[:, 1] = 0\n",
        "print('Updated tensor:', tensor )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 552,
      "metadata": {
        "id": "7oxsQ6IieUqA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum: 21\n",
            "Mean: 3.5\n",
            "Max: 6\n",
            "Min: 1\n"
          ]
        }
      ],
      "source": [
        "# Reduction Operations\n",
        "\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Summation\n",
        "tensor_sum = tensor_sum = torch.sum(tensor) # TODO: Compute Sum of all elements in tensor\n",
        "print(f\"Sum: {tensor_sum}\")\n",
        "\n",
        "# Mean\n",
        "tensor_mean = tensor.float().mean()  # TODO: Compute mean of all elements in tensor. Note: Use .float() for mean\n",
        "print(f\"Mean: {tensor_mean}\")\n",
        "\n",
        "# Max/Min\n",
        "tensor_max = torch.max(tensor) # TODO: Find Max element in tensor\n",
        "tensor_min = torch.min(tensor) # TODO: Find Min element in tensor\n",
        "print(f\"Max: {tensor_max}\")\n",
        "print(f\"Min: {tensor_min}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 553,
      "metadata": {
        "id": "ZKj3Oq3hciS_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor shape: torch.Size([4, 4])\n",
            "Reshaped tensor shape: torch.Size([16])\n",
            "Reshaped tensor shape: torch.Size([2, 8])\n",
            "Original tensor shape: torch.Size([2, 3, 4])\n",
            "Permuted tensor shape: torch.Size([4, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Reshaping\n",
        "\n",
        "x = torch.randn(4, 4)\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "y = x.view(-1)  # TODO: Reshape to a 1D tensor\n",
        "print(\"Reshaped tensor shape:\", y.shape)\n",
        "\n",
        "z = x.view(2, 8)  # TODO: Reshape to a 2x8 tensor\n",
        "print(\"Reshaped tensor shape:\", z.shape)\n",
        "\n",
        "\n",
        "# Permute (reorders dimensions)\n",
        "x = torch.randn(2, 3, 4)\n",
        "x_perm = x.permute(2, 0, 1) # TODO: Swap dimensions in order 2, 0, 1\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "print(\"Permuted tensor shape:\", x_perm.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 554,
      "metadata": {
        "id": "hceRsbDvJy6r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row Concatenated Tensors: tensor([[0.8324, 0.0808, 0.2046, 0.9416],\n",
            "        [0.2212, 0.1959, 0.7160, 0.8438],\n",
            "        [0.0044, 0.9312, 0.4663, 0.5130],\n",
            "        [0.2100, 0.4786, 0.0994, 0.7884],\n",
            "        [0.8453, 0.0433, 0.8272, 0.0238],\n",
            "        [0.3858, 0.5628, 0.5196, 0.9304],\n",
            "        [0.1894, 0.0572, 0.0243, 0.4674],\n",
            "        [0.9973, 0.9375, 0.5517, 0.8392]])\n",
            "Column Concatenated Tensors: tensor([[0.8324, 0.0808, 0.2046, 0.9416, 0.8453, 0.0433, 0.8272, 0.0238],\n",
            "        [0.2212, 0.1959, 0.7160, 0.8438, 0.3858, 0.5628, 0.5196, 0.9304],\n",
            "        [0.0044, 0.9312, 0.4663, 0.5130, 0.1894, 0.0572, 0.0243, 0.4674],\n",
            "        [0.2100, 0.4786, 0.0994, 0.7884, 0.9973, 0.9375, 0.5517, 0.8392]])\n",
            "tensor([[[0.8324, 0.0808, 0.2046, 0.9416],\n",
            "         [0.2212, 0.1959, 0.7160, 0.8438],\n",
            "         [0.0044, 0.9312, 0.4663, 0.5130],\n",
            "         [0.2100, 0.4786, 0.0994, 0.7884]],\n",
            "\n",
            "        [[0.8453, 0.0433, 0.8272, 0.0238],\n",
            "         [0.3858, 0.5628, 0.5196, 0.9304],\n",
            "         [0.1894, 0.0572, 0.0243, 0.4674],\n",
            "         [0.9973, 0.9375, 0.5517, 0.8392]],\n",
            "\n",
            "        [[0.4960, 0.7283, 0.0642, 0.9043],\n",
            "         [0.5864, 0.5779, 0.6419, 0.2625],\n",
            "         [0.4557, 0.0852, 0.4943, 0.4070],\n",
            "         [0.2458, 0.0990, 0.3707, 0.7862]]])\n"
          ]
        }
      ],
      "source": [
        "tensor_one = torch.rand(4, 4)\n",
        "tensor_two = torch.rand(4, 4)\n",
        "# TODO: Concatenate tensor_one and tensor_two row wise\n",
        "row_concatenated_tensor = torch.cat((tensor_one, tensor_two), dim=0)\n",
        "print('Row Concatenated Tensors:', row_concatenated_tensor)\n",
        "\n",
        "# TODO: Concatenate tensor_one and tensor_two column wise\n",
        "col_concatenated_tensor = torch.cat((tensor_one, tensor_two), dim=1)\n",
        "print('Column Concatenated Tensors:', col_concatenated_tensor)\n",
        "\n",
        "tensor_three = torch.rand(4, 4)\n",
        "# TODO: Stack tensors one, two and three along the default dimension (dim=0)\n",
        "stacked_tensor = torch.stack((tensor_one, tensor_two, tensor_three), dim=0)\n",
        "\n",
        "print(stacked_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {
        "id": "60CmbBGmb0gj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "In-place operations\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Added five to  all values of tensor tensor([[6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.]])\n",
            "Subtract five to  all values of tensor tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "#In-place operations\n",
        "tensor = torch.ones(4, 4)\n",
        "print()\n",
        "print('In-place operations')\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "tensor = torch.ones(4,4)\n",
        "# TODO: Add 5 to all values of the\n",
        "tensor.add_(5)\n",
        "print('Added five to  all values of tensor', tensor)\n",
        "\n",
        "# TODO: Subtract 5 to all values of the\n",
        "tensor.sub_(5)\n",
        "print('Subtract five to  all values of tensor', tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 556,
      "metadata": {
        "id": "r8qxH-uyGaC4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Element wise multiplication: tensor([[0.8164, 0.1195, 0.1170, 0.3859],\n",
            "        [0.1041, 0.2886, 0.0690, 0.2557],\n",
            "        [0.0139, 0.4758, 0.0508, 0.9610],\n",
            "        [0.3467, 0.2574, 0.3968, 0.6846]])\n",
            "\n",
            "Dot product tensor: tensor([[2.1595, 1.1936, 1.0042, 1.5336],\n",
            "        [1.4953, 1.3365, 0.6483, 1.7033],\n",
            "        [1.4429, 1.1127, 0.6044, 1.2114],\n",
            "        [1.6688, 1.4107, 0.9613, 1.8755]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Multiplying tensors\n",
        "\n",
        "# TODO: Given two tensors, do an element wise multiplication\n",
        "# Hint: There is more than one way to do this\n",
        "tensor_one = torch.rand(4, 4)\n",
        "tensor_two = torch.rand(4, 4)\n",
        "\n",
        "element_wise_tensor = tensor_one * tensor_two\n",
        "print(\"Element wise multiplication:\", element_wise_tensor)\n",
        "print()\n",
        "\n",
        "# TODO: Compute the dot product of the two tensors\n",
        "# Hint: There is more than one way to do this\n",
        "dot_product_tensor = torch.matmul(tensor_one, tensor_two)\n",
        "print(\"Dot product tensor:\", dot_product_tensor)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85ZVnKXcnPG"
      },
      "source": [
        "### Section 1.4 Broadcasting\n",
        "Broadcasting in PyTorch is a useful feature that lets you perform operations on tensors of incompatible shapes without manually reshaping them. PyTorch automatically expands smaller tensors so their shapes are compatible for element-wise operations.\n",
        "\n",
        "You can read the details of these rules here: https://pytorch.org/docs/stable/notes/broadcasting.html\n",
        "\n",
        "\n",
        " In general you never need broadcasting as you can always be explicit with your tensor shapes. At first, broadcasting can feel like arbitrary rules but as you write more PyTorch you'll start to find them convienent particularly when working with training batches.\n",
        "\n",
        " Below we show some examples of broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 557,
      "metadata": {
        "id": "iE8djsysaUgz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Broadcasting example 1:\n",
            " tensor([[11, 12],\n",
            "        [13, 14]])\n",
            "\n",
            "tensor([[11, 22],\n",
            "        [13, 24]])\n",
            "Broadcasting example 2:\n",
            " tensor([[11, 22],\n",
            "        [13, 24]])\n",
            "\n",
            "Broadcasting example 3:\n",
            " tensor([[10, 20, 30],\n",
            "        [20, 40, 60],\n",
            "        [30, 60, 90]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Broadcasting\n",
        "import torch\n",
        "# Example 1: Adding a scalar to a tensor\n",
        "tensor = torch.tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
        "scalar = torch.tensor(10)               # shape ()\n",
        "\n",
        "result = tensor + scalar  # Broadcasting scalar to shape (2, 2)\n",
        "# result: [[11, 12],\n",
        "#          [13, 14]]\n",
        "print(f\"Broadcasting example 1:\\n {result}\\n\")\n",
        "\n",
        "# Example 2: Adding a vector to a matrix (1D + 2D Tensor)\n",
        "a = torch.tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
        "b = torch.tensor([10, 20])         # shape (2,)\n",
        "\n",
        "result = a + b  # b is broadcast to shape (2, 2)\n",
        "print(result)\n",
        "# Output:\n",
        "# tensor([[11, 22],\n",
        "#         [13, 24]])\n",
        "print(f\"Broadcasting example 2:\\n {result}\\n\")\n",
        "\n",
        "# Example 3 â€” Column Vector + Matrix\n",
        "a = torch.tensor([[1], [2], [3]])  # shape (3, 1)\n",
        "b = torch.tensor([[10, 20, 30]])   # shape (1, 3)\n",
        "\n",
        "result = a * b  # a broadcast to (3, 3), b broadcast to (3, 3)\n",
        "print(f\"Broadcasting example 3:\\n {result}\\n\")\n",
        "# Output:\n",
        "# tensor([[10, 20, 30],\n",
        "#         [20, 40, 60],\n",
        "#         [30, 60, 90]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 558,
      "metadata": {
        "id": "tF-ehnUq5Fyt"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[558]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m a = torch.ones((\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      3\u001b[39m b = torch.ones((\u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBroadcasting example 4:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Will give a runtime error\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# Examples 4 - Mismatched Dimensions\n",
        "a = torch.ones((2, 3))\n",
        "b = torch.ones((3, 2))\n",
        "\n",
        "result = a + b\n",
        "print(f\"Broadcasting example 4:\\n {result}\\n\") # Will give a runtime error\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygoOUZyx1Q82"
      },
      "source": [
        "### TODO: Please answer the following questions.\n",
        "\n",
        "1) Predict the shape:\n",
        "\n",
        "    a = torch.ones((3, 1))\n",
        "    b = torch.ones((1, 4))\n",
        "    result = a + b\n",
        "\n",
        "Ans: (3, 4)\n",
        "\n",
        "\n",
        "2) Predict the shape:\n",
        "\n",
        "    a = torch.ones((2, 3))\n",
        "    b = torch.ones((2, 1))\n",
        "    result = a + b\n",
        "Ans: (2, 3)\n",
        "\n",
        "3) What is the output?\n",
        "\n",
        "    a = torch.tensor([[1], [2], [3]])  # shape (3, 1)\n",
        "    b = torch.tensor([10, 20])         # shape (2,)\n",
        "    result = a + b\n",
        "\n",
        "Ans: The matrix will have shape (3, 2)\n",
        "([[11, 21],\n",
        "        [12, 22],\n",
        "        [13, 23]])\n",
        "\n",
        "4) Will the following code run? Please explain why or why not.\n",
        "    \n",
        "    \n",
        "    a = torch.ones((2, 2))\n",
        "    b = torch.ones((3, 1))\n",
        "\n",
        "    result = a + b\n",
        "\n",
        "Ans: There will be an error as no dimensions between a and b match and neither are 1. The shapes a and b are not broadcast compatible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NrFCWLuPSqR"
      },
      "source": [
        "## Section 2: Automatic Differentiaion with Logistic Regression\n",
        "\n",
        "In this section, we'll use logistic regression as an example to explain the entire flow of building and training a model. Logistic Regression was introduced in class, but we will now explore how it more detail. Specifically, we will build the model from scratch using PyTorch modules, and train it on our data using automatic differentiation. This process invloves implement implementing the model's forward pass, selecting the appropriate loss and optimizer components, and then writing a training loop to optimize the model relative to our dataset.\n",
        "\n",
        "**Note: There are no TODOs for Section 2 but it is critical you read, run, and understand this code or in order to understand what you need for Section 3 and future assignments.**\n",
        "\n",
        "### Iris Dataset\n",
        "\n",
        "To train our logistic regression model we will use a classic machine learning dataset - the Iris dataset. It containes 150 instances of iris flowers categorized by three species: Setosa, Versicolor, and Virginica. Each flower is describes by four numerical features:\n",
        "\n",
        "\n",
        "*   Sepal length (cm)\n",
        "*   Sepal width (cm)\n",
        "*   Petal length (cm)\n",
        "*   Petal width (cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAvnSFsLRieZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "csv_path = \"iris.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xqmZhpalo23"
      },
      "source": [
        "### Section 2.1 `Dataset` and `DataLoader`\n",
        "\n",
        "In deep learning, handling large datasets efficiently is crucial. During training, doing gradient calculations on an entire large dataset can be time consuming. So a better way to handle large datasets is to divide samples into smaller batches and do the calculations individually. PyTorch provides `Dataset` and `DataLoader` to streamline this process:\n",
        "\n",
        "- **`Dataset` Class**: Helps organize and preprocess data by defining how to load samples. It enables transformations, label encoding, and normalization before passing data to a model.\n",
        "- **`DataLoader` Class**: Manages batch loading, shuffling, and parallel processing, optimizing data feeding into the training loop.\n",
        "\n",
        "This structured approach organizes your code, improves performance, and ensures smooth model training, especially for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0xknXOypejw"
      },
      "outputs": [],
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Initialize the IrisDataset.\n",
        "\n",
        "        Args:\n",
        "            X (dtype -- numpy.ndarray): Features (sepal length, sepal width, petal length, petal width)\n",
        "            y (dtype -- numpy.ndarray): Target (species)\n",
        "        \"\"\"\n",
        "        # We first convert the features ad labels to pytorch tensors\n",
        "        # We convert feature data (X) to float32 data type as PyTorch models (like nn.Linear) expect this format.\n",
        "        # We convert target data (y) to int64 data type to ensure compatibility with PyTorch's loss functions.\n",
        "        self.x = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y.astype(np.int64))\n",
        "\n",
        "        # Store the number of samples in the dataset\n",
        "        self.n_samples = X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Allows for indexing. For example, we can do dataset[0]\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Allows us to call len(dataset)\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6HIgIP9bP0P"
      },
      "source": [
        "We will now load the dataset, preprocess it and create instances of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbSVlY8ga6Ts"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (120, 4), Testing set: (30, 4)\n"
          ]
        }
      ],
      "source": [
        "# Define the column names for the dataset\n",
        "column_names = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"]\n",
        "\n",
        "# Load the data from the CSV file (above cells) into a Pandas DataFrame\n",
        "data = pd.read_csv(csv_path, names=column_names, header=0)\n",
        "\n",
        "# Encode the species target (categorical data) into numerical values\n",
        "# 0 -> Iris-setosa\n",
        "# 1 -> Iris-setosa\n",
        "# 2 -> Iris-virginica\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"Species\"] = label_encoder.fit_transform(data[\"Species\"])\n",
        "\n",
        "# Seperate out the columns into features (all columns except the last one) and target (the last column)\n",
        "features = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = data[features].values  # Features\n",
        "y = data[\"Species\"].values   # Target\n",
        "y = y.flatten() # This ensures that out targets are a 1D array -- our loss function will require this!\n",
        "\n",
        "# Split dataset into training and testing sets using train_test_split -- We are using 20% of the samples as test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OFw_XxTrW2K"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = IrisDataset(X_train, y_train)\n",
        "test_dataset = IrisDataset(X_test, y_test)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEClxYsGf4tF"
      },
      "source": [
        "### Section 2.2 Create a LogisticRegression Module\n",
        "\n",
        "Logistic regression is a simple yet effective classification algorithm that applies a linear transformation to input features and uses a softmax activation to predict class probabilities. To help you get started, we are providing demo/sample code for a logistic regression implementation. This will give you a basic structure to build upon as you develop your understanding of logistic regression.\n",
        "\n",
        "In this section, we will create a simple logistic regression class using PyTorch's nn.Linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6JS7MgdgTse"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        # Define a single fully connected layer with a bias (linear transformation)\n",
        "        # This maps input features (input_dim) to output classes (num_classes)\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: Apply the linear transformation to input data\n",
        "        # Note: We do not use an activation function here because\n",
        "        # PyTorch's CrossEntropyLoss automatically applies softmax\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL7vtXodofjI"
      },
      "source": [
        "### Section 2.3 Create Our Model and Components\n",
        "\n",
        "Now that we have defined our logistic regression class, we need to train it on our dataset. PyTorch provides many pre-built implementations of common deep learning components to make this relatively easy to do. However, a lot is happening behind the scenes so let's break it down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFMiGST5kU08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(\n",
            "  (linear): Linear(in_features=4, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get the number of features and classes\n",
        "input_dim = 4  # Number of features -- You can automatically determine from the data using `X_train.shape[1]`\n",
        "num_classes = 3  # Number of categories in dataset -- You can automatically determine from the data using `len(np.unique(y))`\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LogisticRegression(input_dim, num_classes)  # Create an instance of our logistic regression model\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent optimizer with a learning rate of 0.01\n",
        "\n",
        "# Let's see what model we initialized\n",
        "print(model)  # This prints the structure of our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQRVSwtB85vw"
      },
      "source": [
        "Above, we initialize an instance of the logistic regression model we just created. We also define a loss/objective function to measure how well the model is performing and an optimizer to update the model's parameters based on gradients computed during backpropagation.\n",
        "\n",
        "We use a PyTorch built-in for the loss function and optimizer which are similiar to the squared error loss and gradient descent alogirthms we discussed in lecture. Cross Entropy is a loss with better properties for classification and will make our training more smooth and consistent. While \"Stochastic\" Gradient Descent is the gradient descent we've seen but implies a single training datapoint is used instead of all the datapoints (more on this later). In practice, it's common to use these built-ins instead of writing them from scratch, but PyTorch makes it relatively easy to extend and define your own if you want to create a custom loss function or optimization algorithm. Notice how we take the `parameters()` of the model and provide them to our optimizer. This tells the optimization algorithm which tensors need to updated on each iteration of our training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSwiacl6NK4o"
      },
      "source": [
        "### Section 2.4 The Training Loop\n",
        "\n",
        "**Note: If you've been skimming the prior sections be sure to slow down and understand this one in detail. This content is incredibly important and likely to show up on an exam.**\n",
        "\n",
        "Now, we will see the power of PyTorch with *automatic differentiation.* In the background PyTorch tracks all of the operations performed on any tensor that you create and builds a computational graph which tracks the influence of each operation on downstream values. This tracking occurs *across* variable assignments so the graph is reflective of your entire program from input tensor to final output tensor. In deep learning, the final tensor is usually your computed loss for a subset (batch) of the training data. Then with a single call to the `backward()` routine **the entire backpropagation algorithm is run** to compute the gradients for the computation graph. Below, we put everything together: the model, training components, dataloader, etc. Read through the code and run it, then we will break it down.\n",
        "\n",
        "A few terms will be helpful before we move forward:\n",
        "\n",
        "* **epoch**: One complete forward and backward pass of all samples in the training set.\n",
        "\n",
        "* **batch_size**: The number of training samples in a single forward and backward pass.\n",
        "\n",
        "* **number of iterations**: The total number of passes, where each pass processes batch_size number of samples.\n",
        "\n",
        "For example, if we have 100 samples and set `batch_size = 20`, then `100 / 20 = 5` iterations are needed for one complete epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbVSwajKhWA6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 1.0185\n",
            "Epoch [20/100], Loss: 0.6758\n",
            "Epoch [30/100], Loss: 0.6589\n",
            "Epoch [40/100], Loss: 0.4772\n",
            "Epoch [50/100], Loss: 0.4862\n",
            "Epoch [60/100], Loss: 0.5004\n",
            "Epoch [70/100], Loss: 0.4165\n",
            "Epoch [80/100], Loss: 0.3867\n",
            "Epoch [90/100], Loss: 0.4435\n",
            "Epoch [100/100], Loss: 0.3415\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 100  # Number of times the entire dataset is passed through the model\n",
        "for epoch in range(num_epochs):\n",
        "    # We loop over train_loader to process batches efficiently\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Forward pass: Compute model predictions\n",
        "        outputs = model(inputs)  # Pass inputs through the model\n",
        "        loss = criterion(outputs, labels)  # Compute loss between predictions and actual labels\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Reset gradients to zero before backpropagation\n",
        "        loss.backward()  # Compute gradients of the loss with respect to model parameters\n",
        "        optimizer.step()  # Update model parameters using computed gradients\n",
        "\n",
        "    # Print loss every 10 epochs to monitor training progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  # Print epoch number and current loss value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6js-HaZ10atF"
      },
      "source": [
        "The first few lines are boilerplate which set up our training loop and call our `Dataloader` that we created earlier to get a *batch* of the data. In class, we showed how each iteration of gradient descent updated the model parameters for all the training datapoints. Often in practice, our machine does not have enough memory to do this (particularly for big models and large datasets). So we instead *estimate* the true gradient with a subset of the data (batch) and update our parameters incrementally. Confusingly, this is referred to as **mini-batch gradident descent** in contrast to using *all* training datapoints, which is **batch gradient descent.** There are theoretical implications of doing one versus the other which is why people distinguish, so to summarize:\n",
        "\n",
        "| Term                       | Description                                                                 |\n",
        "|----------------------------|-----------------------------------------------------------------------------|\n",
        "| Batch Gradient Descent     | Uses **all** training data to compute the gradient and update parameters.   |\n",
        "| Mini-Batch Gradient Descent| Uses a **subset** (mini-batch) of the training data to estimate the gradient. |\n",
        "| Stochastic Gradient Descent| Uses **one** training example at a time to estimate the gradient.           |\n",
        "\n",
        "The next couple lines call our model on the training batch and compute the loss for this batch. The three lines that follow are crucial:\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "The first line does nothing on the first iteration, but on subsequent iterations clears out the gradients computed on the previous batch. The next line performs backpropagation to compute the gradients for the current batch which are accumulated on each of the models' individual parameters. In the next line the optimizer computes the updates for each of these parameters relative to the gradients and applies them to each parameter of our model (recall we connected them earlier when we initialized the optimizer).\n",
        "\n",
        "In summary, the training process involves repeatedly passing the training data through the model, computing the loss, calculating gradients, and updating the model parameters. This training loop iterates over the dataset multiple times, adjusting the model's parameters to minimize the loss. By following this structure, you can train a logistic regression model to classify iris flowers based on their features. Each epoch represents a full pass through the dataset, and the optimizer updates the weights in a way that reduces the classification error over time. This iterative process helps the model learn the optimal weights for making predictions relative to the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS1uLn60nQO9"
      },
      "source": [
        "# Section 3: Creating a Multi-Layer Perceptron Using the Titanic dataset\n",
        "In the previous sections, we reviewed the basics of PyTorch from creating tensors to creating a basic model. In this section, we will ask you to put it all together. We will ask you train a multi-layer perceptron to perform classification on the titanic dataset. We will ask you to do some data cleaning, create a model, train and test the model, do some experimentation and present the results.\n",
        "\n",
        "\n",
        "## Titanic Dataset\n",
        "The Titanic dataset is a dataset containing information of the passengers of the RMS Titanic, a British passanger ship which famously sunk upon hitting an iceberg. The dataset can be used for binary classification, predicting whether a passenger survived or not.  The dataset includes demographic, socio-economic, and onboard information such as:\n",
        "\n",
        "\n",
        "- Survived (Target Variable): 0 = No, 1 = Yes\n",
        "- Pclass (Passenger Class): 1st, 2nd, or 3rd class\n",
        "- Sex: Male or Female\n",
        "- Age: Passenger's age in years\n",
        "- SibSp: Number of siblings/spouses aboard\n",
        "- Parch: Number of parents/children aboard\n",
        "- Fare: Ticket fare price\n",
        "- Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 561,
      "metadata": {
        "id": "DzKPNapBVW-v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 589,
      "metadata": {
        "id": "TlscqXNBd17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhg1dBCFtatI"
      },
      "source": [
        "### Section 3.1: Process data for modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 590,
      "metadata": {
        "id": "U0vmFWcXspVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (712, 7), Testing set: (179, 7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1888/150598377.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipykernel_1888/150598377.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# TODO : Handle missing values for \"Age\" and \"Embarked\"\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# TODO: Encode categorical features \"Sex\" and \"Embarked\"\n",
        "# Hint: Use LabelEncoder (check imports)\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Sex\"] = label_encoder.fit_transform(df[\"Sex\"])\n",
        "df[\"Embarked\"] = label_encoder.fit_transform(df[\"Embarked\"])\n",
        "\n",
        "\n",
        "# TODO: Select features and target\n",
        "X = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "\n",
        "# TODO: Normalize numerical features in X\n",
        "# Hint: Use StandardScaler()\n",
        "scalar = StandardScaler()\n",
        "X = scalar.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErqCEhnbtk3q"
      },
      "source": [
        "### Section 3.2 Create a Dataset Class with the Previous Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 591,
      "metadata": {
        "id": "iyzpNdidVN9L"
      },
      "outputs": [],
      "source": [
        "class TitanicDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        # TODO: initialize X, y as tensors\n",
        "        \n",
        "        self.X = self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = self.y = torch.tensor(y.values if hasattr(y, 'values') else y, dtype=torch.float64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "# TODO: Instantiate the dataset classes\n",
        "train_dataset = TitanicDataset(X_train, y_train)\n",
        "test_dataset = TitanicDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "# TODO: Create Dataloaders using the datasets\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQVqXHkuS2q"
      },
      "source": [
        "### Section 3.3 Create a MLP class\n",
        "In this section we will create a multi-layer perceptron with the following specification.\n",
        "We will have a total of three fully connected layers.\n",
        "\n",
        "\n",
        "1.   Fully Connected Layer of size (7, 64) followed by ReLU\n",
        "2.   Full Connected Layer of Size (64, 32) followed by ReLU\n",
        "3. Full Connected Layer of Size (32, 1) followed by Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 592,
      "metadata": {
        "id": "dnAEHi5QVp0k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TitanicMLP(\n",
            "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
            "  (reLU1): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (reLU2): ReLU()\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TitanicMLP(\n",
              "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
              "  (reLU1): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (reLU2): ReLU()\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 592,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TitanicMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TitanicMLP, self).__init__()\n",
        "        # TODO: Define Layers\n",
        "        self.fc1 = nn.Linear(7, 64)\n",
        "        self.reLU1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.reLU2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Complete implemenation of forward\n",
        "        x = self.fc1(x)\n",
        "        x = self.reLU1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.reLU2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "model = TitanicMLP()\n",
        "print(model)\n",
        "\n",
        "# TODO: Move the model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfFKYNlj2Bhg"
      },
      "source": [
        "### Section 3.4 : Writing a training and testing loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 593,
      "metadata": {
        "id": "0yRL8RJoVyxR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.6614\n",
            "Epoch [2/20], Loss: 0.5127\n",
            "Epoch [3/20], Loss: 0.4470\n",
            "Epoch [4/20], Loss: 0.4290\n",
            "Epoch [5/20], Loss: 0.4205\n",
            "Epoch [6/20], Loss: 0.4102\n",
            "Epoch [7/20], Loss: 0.4069\n",
            "Epoch [8/20], Loss: 0.4022\n",
            "Epoch [9/20], Loss: 0.4028\n",
            "Epoch [10/20], Loss: 0.3958\n",
            "Epoch [11/20], Loss: 0.3970\n",
            "Epoch [12/20], Loss: 0.3951\n",
            "Epoch [13/20], Loss: 0.3888\n",
            "Epoch [14/20], Loss: 0.3897\n",
            "Epoch [15/20], Loss: 0.3906\n",
            "Epoch [16/20], Loss: 0.3873\n",
            "Epoch [17/20], Loss: 0.3855\n",
            "Epoch [18/20], Loss: 0.3859\n",
            "Epoch [19/20], Loss: 0.3844\n",
            "Epoch [20/20], Loss: 0.3830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1888/3031375006.py:36: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend()\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train_model(train_loader, num_epochs, learning_rate):\n",
        "  # we have provided the loss and optimizer below\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      total_loss = 0\n",
        "      # TODO: Compute the Gradient and Loss by iterating train_loader\n",
        "      # TODO: Print and store loss at each epoch\n",
        "      for i, (inputs, labels) in enumerate(train_loader):\n",
        "         inputs, labels = inputs.to(device), labels.to(device)\n",
        "         loss = criterion(model(inputs).squeeze(), labels.float())\n",
        "\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         total_loss += loss.item()\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      train_losses.append(avg_loss)\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "  return train_losses\n",
        "\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "train_losses = train_model(train_loader, num_epochs, learning_rate)\n",
        "\n",
        "# TODO: Plot the Training Loss Curve by (Epoch # on x-axis and loss on y-axis)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, marker='o', linestyle='-')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 594,
      "metadata": {
        "id": "krHbZGHlV5VV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 82.12%\n"
          ]
        }
      ],
      "source": [
        "def test_model():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # When we are doing inference on a model, we do not need to keep track of gradients\n",
        "  # torch.no_grad() indicates to pytorch to not store gradients for more efficent inference\n",
        "  with torch.no_grad():\n",
        "    # TODO: Iterate through test_loader and perform a forward pass to compute predictions\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs).squeeze()\n",
        "      predictions = (outputs >=0.5)\n",
        "      correct = correct + (predictions == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "  print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "test_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1Ac-rR4TdZ"
      },
      "source": [
        "### Section 3.5: Hyperparameter Tuning\n",
        "This section is open-ended. We want you to experiment with different setting for training such as the learning rate, using a different optimizer, and using different MLP architecture. Report how you went about hyper-paramater tuning and provide the code with comments. Then provide a table with settings that you experimented with. The table should present 5 different setting with which you trained the architecture. Finally, write up a brief analysis on your findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oHqFfJDWCkK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   learning_rate optimizer  batch_size  architecture   accuracy\n",
            "0          0.010      adam          32      [64, 32]  80.446927\n",
            "1          0.010      adam          16  [64, 64, 32]  81.005587\n",
            "2          0.010   rmsprop          16      [64, 32]  82.122905\n",
            "3          0.010       sgd          16      [64, 32]  78.212291\n",
            "4          0.001      adam          16      [64, 32]  81.564246\n"
          ]
        }
      ],
      "source": [
        "# TODO: Hyper parameter code\n",
        "\n",
        "architectures = [\n",
        "    [64, 32],           \n",
        "    [64, 32],          \n",
        "    [64, 32],           \n",
        "    [64, 64, 32],     \n",
        "    [64, 32]                 \n",
        "]\n",
        "\n",
        "variations = [\n",
        "    {'learning_rate': 0.01, 'optimizer': 'adam', 'batch_size': 32, 'architecture': architectures[1]},  \n",
        "    {'learning_rate': 0.01, 'optimizer': 'adam', 'batch_size': 16, 'architecture': architectures[3]}, \n",
        "    {'learning_rate': 0.01, 'optimizer': 'rmsprop', 'batch_size': 16, 'architecture': architectures[2]}, \n",
        "    {'learning_rate': 0.01, 'optimizer': 'sgd', 'batch_size': 16, 'architecture': architectures[0]},     \n",
        "    {'learning_rate': 0.001, 'optimizer': 'adam', 'batch_size': 16, 'architecture': architectures[4]},     \n",
        "]\n",
        "\n",
        "class FlexibleMLP(nn.Module):\n",
        "    def __init__(self, architecture):\n",
        "        super(FlexibleMLP, self).__init__()\n",
        "        layers = []\n",
        "        in_features = 7\n",
        "        for out_features in architecture:\n",
        "            layers.append(nn.Linear(in_features, out_features))\n",
        "            layers.append(nn.ReLU())\n",
        "            in_features = out_features\n",
        "        layers.append(nn.Linear(in_features, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "def get_optimizer(opt_name, model, lr):\n",
        "    if opt_name == \"adam\":\n",
        "        return optim.Adam(model.parameters(), lr=lr)\n",
        "    elif opt_name == \"rmsprop\":\n",
        "        return optim.RMSprop(model.parameters(), lr=lr)\n",
        "    elif opt_name == \"sgd\":\n",
        "        return optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "def train_and_evaluate(config):\n",
        "    model = FlexibleMLP(config['architecture']).to(device)\n",
        "    optimizer = get_optimizer(config['optimizer'], model, config['learning_rate'])\n",
        "    criterion = nn.BCELoss()\n",
        "    loader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "results = []\n",
        "for config in variations:\n",
        "    acc = train_and_evaluate(config)\n",
        "    config_copy = config.copy()\n",
        "    config_copy['accuracy'] = acc\n",
        "    results.append(config_copy)\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vaKzcze5Nru"
      },
      "source": [
        "Please explain your hyper-parameter tuning:\n",
        "\n",
        "[TODO: Insert explanation here]\n",
        "\n",
        "I performed hyperparameter tuning to explore how changes in key training parameters affect model performance. Specifically, I experimented with varying the learning rate (both smaller and larger than the baseline), using different optimizers, modifying the model architecture, and adjusting the batch size. The goal was to identify which combination of these factors leads to the highest testing accuracy. This process allowed me to evaluate the impact of each parameter and determine the most effective setup for accurate predictions on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoZ329QS5g3H"
      },
      "source": [
        "Please provide a table with 5 settings:\n",
        "\n",
        "[TODO: Enter table here]\n",
        "| learning_rate | optimizer | batch_size |   architecture   |  accuracy   |\n",
        "|---------------|-----------|------------|------------------|-------------|\n",
        "|     0.010     | adam      |     32     |    [64, 32]      |  80.446927  |\n",
        "|     0.010     | adam      |     16     |  [64, 64, 32]    |  81.005587  |\n",
        "|     0.010     | rmsprop   |     16     |    [64, 32]      |  82.122905  |\n",
        "|     0.010     | sgd       |     16     |    [64, 32]      |  78.212291  |\n",
        "|     0.001     | adam      |     16     |    [64, 32]      |  81.564246  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNz-Mq_K5pSq"
      },
      "source": [
        "Please provide your analysis here:\n",
        "\n",
        "[TODO: Enter Analysis Here]\n",
        "\n",
        "From the results, using RMSprop as the optimizer led to the highest accuracy (~82.12%), outperforming both Adam and SGD with the same architecture and learning rate. This suggests that switching to RMSprop had the most significant positive impact on performance. While Adam performed consistently well across different settings, SGD lagged behind with noticeably lower accuracy (~75.98%). Overall, the choice of optimizer had the greatest influence on model performance in this set of experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
